{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import keras_tuner as kt\n",
    "from tensorflow import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "import datetime\n",
    "import sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n"
     ]
    }
   ],
   "source": [
    "print(tf.config.list_physical_devices('GPU'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "IMPORT_COUNT = 5000000\n",
    "TEST_COUNT = 10000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random seed is: 71926\n"
     ]
    }
   ],
   "source": [
    "# Generate random seed\n",
    "#myrand=np.random.randint(1, 99999 + 1)\n",
    "myrand=71926\n",
    "np.random.seed(myrand)\n",
    "tf.random.set_seed(myrand)\n",
    "print(\"Random seed is:\",myrand)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "RNG_OUTPUT_FILENAME=\"mersenne_twist_states.txt\"\n",
    "df = np.genfromtxt(RNG_OUTPUT_FILENAME,delimiter='\\n',dtype='uint64', max_rows=IMPORT_COUNT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#calculates how many bits are in the output.\n",
    "BIT_WIDTH=np.ceil(np.log2(np.amax(df))).astype(int)\n",
    "# convert the generated numbers to binary sequences\n",
    "df_as_bits =(df[:,None] & (1 << np.arange(BIT_WIDTH,dtype='uint64')) > 0).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#convert the data into inputs and outputs\n",
    "df_as_frames = np.array([df_as_bits[[X - 624, X - 624 + 1, X- 624 +397, X]] for X in range(624, df_as_bits.shape[0])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# shuffle the data frames\n",
    "indicies = np.arange(df_as_frames.shape[0],dtype='uint64')\n",
    "np.random.shuffle(indicies)\n",
    "df_as_frames=df_as_frames[indicies]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert the data into inputs and outputs\n",
    "y = df_as_frames[:,-1,:]\n",
    "X = df_as_frames[:,:-1,]\n",
    "X = X.reshape([X.shape[0], X.shape[1]*X.shape[2]])[:, 31:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data into train and test data\n",
    "X_train = X[TEST_COUNT:]\n",
    "X_test = X[:TEST_COUNT]\n",
    "y_train = y[TEST_COUNT:]\n",
    "y_test = y[:TEST_COUNT]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model(hp):\n",
    "    LOSS=\"binary_crossentropy\"\n",
    "    model = Sequential()\n",
    "    model.add(Dense(96, activation='relu',input_shape=[X.shape[1]] ))\n",
    "    model.add(Dense(y.shape[1], activation='sigmoid'))\n",
    "    \n",
    "    opt = keras.optimizers.Nadam(\n",
    "        learning_rate=hp.Float(\"learning_rate\", 10**(-5), 10**(-2),sampling=\"log\"),\n",
    "        epsilon=hp.Float(\"epsilon\",1e-7,1e-4,sampling=\"log\"),\n",
    "        beta_1=hp.Float(\"beta_1\",.8,.9999,sampling=\"reverse_log\"),\n",
    "        beta_2=hp.Float(\"beta_2\",.8,.9999,sampling=\"reverse_log\"),\n",
    "        )\n",
    "    model.compile(optimizer=opt, loss=LOSS,metrics=['binary_accuracy'])\n",
    "    model.summary()\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#define callback functions\n",
    "stopEarly = tf.keras.callbacks.EarlyStopping(\n",
    "    monitor='val_binary_accuracy', min_delta=.001, patience=10, verbose=0, mode='auto', restore_best_weights=False\n",
    ")\n",
    "\n",
    "log_dir = \"tmp/hyperparameters_twisting/\"+datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "tensorboard_callback = keras.callbacks.TensorBoard(log_dir=log_dir, histogram_freq=1,profile_batch=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract a short set from the training for hyper parameter tuning\n",
    "X_train_short= X_train[:1000000]\n",
    "y_train_short= y_train[:1000000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Reloading Tuner from .\\tmp/twisting\\tuner0.json\n",
      "Results summary\n",
      "Results in .\\tmp/twisting\n",
      "Showing 10 best trials\n",
      "<keras_tuner.engine.objective.Objective object at 0x0000029D8D3B77F0>\n",
      "Trial summary\n",
      "Hyperparameters:\n",
      "learning_rate: 0.01\n",
      "epsilon: 8.517143018543503e-05\n",
      "beta_1: 0.8787368405865883\n",
      "beta_2: 0.9486251178169223\n",
      "Score: 1.0\n",
      "Trial summary\n",
      "Hyperparameters:\n",
      "learning_rate: 0.01\n",
      "epsilon: 8.781877460199428e-06\n",
      "beta_1: 0.9159972966614436\n",
      "beta_2: 0.9719095083753959\n",
      "Score: 1.0\n",
      "Trial summary\n",
      "Hyperparameters:\n",
      "learning_rate: 0.0035977846628660187\n",
      "epsilon: 2.3823395017282265e-06\n",
      "beta_1: 0.9398678587731861\n",
      "beta_2: 0.9693012738278074\n",
      "Score: 0.9836973547935486\n",
      "Trial summary\n",
      "Hyperparameters:\n",
      "learning_rate: 0.002813155631740426\n",
      "epsilon: 6.86915529734392e-06\n",
      "beta_1: 0.933608723098096\n",
      "beta_2: 0.9999\n",
      "Score: 0.9688019752502441\n",
      "Trial summary\n",
      "Hyperparameters:\n",
      "learning_rate: 0.01\n",
      "epsilon: 0.0001\n",
      "beta_1: 0.8045360648031332\n",
      "beta_2: 0.9114469946180094\n",
      "Score: 0.9687929749488831\n",
      "Trial summary\n",
      "Hyperparameters:\n",
      "learning_rate: 0.0031481389496828293\n",
      "epsilon: 3.719732285684735e-06\n",
      "beta_1: 0.9082640055581104\n",
      "beta_2: 0.9305927723063641\n",
      "Score: 0.9375465512275696\n",
      "Trial summary\n",
      "Hyperparameters:\n",
      "learning_rate: 0.0015678768485970567\n",
      "epsilon: 1.0335751928693037e-06\n",
      "beta_1: 0.9030394871347484\n",
      "beta_2: 0.9999\n",
      "Score: 0.9219712615013123\n",
      "Trial summary\n",
      "Hyperparameters:\n",
      "learning_rate: 0.0008093262370610817\n",
      "epsilon: 3.824434879437115e-06\n",
      "beta_1: 0.9756433271188122\n",
      "beta_2: 0.967937764311313\n",
      "Score: 0.9219329357147217\n",
      "Trial summary\n",
      "Hyperparameters:\n",
      "learning_rate: 0.0005155196749126169\n",
      "epsilon: 1.4474147394263357e-07\n",
      "beta_1: 0.8859703363827179\n",
      "beta_2: 0.9377438453637269\n",
      "Score: 0.8952552676200867\n",
      "Trial summary\n",
      "Hyperparameters:\n",
      "learning_rate: 0.001950816046384373\n",
      "epsilon: 2.3767858312959852e-07\n",
      "beta_1: 0.8204919675521625\n",
      "beta_2: 0.9205433033917699\n",
      "Score: 0.889145016670227\n",
      "CPU times: total: 312 ms\n",
      "Wall time: 549 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Tuning the hyper parameters\n",
    "\n",
    "tuner = kt.tuners.bayesian.BayesianOptimization(build_model,'binary_accuracy',25,project_name=\"tmp/twisting\", seed=myrand)\n",
    "\n",
    "while tuner.remaining_trials>0:\n",
    "    try:\n",
    "        tuner.search(X_train_short, y_train_short,batch_size=2048, epochs=100, validation_data=(X_test,y_test),callbacks=[stopEarly,tensorboard_callback])\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "tuner.results_summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense (Dense)               (None, 96)                6336      \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 32)                3104      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 9,440\n",
      "Trainable params: 9,440\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'learning_rate': 0.01,\n",
       " 'epsilon': 8.517143018543503e-05,\n",
       " 'beta_1': 0.8787368405865883,\n",
       " 'beta_2': 0.9486251178169223}"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_hps = tuner.get_best_hyperparameters(num_trials = 1)[0]\n",
    "# use the best model for training\n",
    "model = tuner.hypermodel.build(best_hps)\n",
    "\n",
    "best_hps.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, X = X_train, Y=y_train, epochs=100, batch_size=2048,verbose=1, log_dir = \"tmp/dense_model/\"):\n",
    "    log_dir += datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "    tensorboard_callback = keras.callbacks.TensorBoard(log_dir=log_dir, histogram_freq=1,profile_batch=0)\n",
    "    model.fit(X, Y, validation_data=(X_test, y_test), epochs=epochs, batch_size=batch_size,callbacks=[tensorboard_callback],verbose=verbose)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "2437/2437 [==============================] - 14s 4ms/step - loss: 0.2712 - binary_accuracy: 0.8180 - val_loss: 0.1852 - val_binary_accuracy: 0.8711\n",
      "Epoch 2/20\n",
      "2437/2437 [==============================] - 10s 4ms/step - loss: 0.1506 - binary_accuracy: 0.8951 - val_loss: 0.1149 - val_binary_accuracy: 0.9205\n",
      "Epoch 3/20\n",
      "2437/2437 [==============================] - 10s 4ms/step - loss: 0.1091 - binary_accuracy: 0.9219 - val_loss: 0.1095 - val_binary_accuracy: 0.9217\n",
      "Epoch 4/20\n",
      "2437/2437 [==============================] - 10s 4ms/step - loss: 0.0975 - binary_accuracy: 0.9316 - val_loss: 0.0662 - val_binary_accuracy: 0.9528\n",
      "Epoch 5/20\n",
      "2437/2437 [==============================] - 10s 4ms/step - loss: 0.0651 - binary_accuracy: 0.9540 - val_loss: 0.0636 - val_binary_accuracy: 0.9559\n",
      "Epoch 6/20\n",
      "2437/2437 [==============================] - 10s 4ms/step - loss: 0.0470 - binary_accuracy: 0.9675 - val_loss: 0.0440 - val_binary_accuracy: 0.9688\n",
      "Epoch 7/20\n",
      "2437/2437 [==============================] - 10s 4ms/step - loss: 0.0436 - binary_accuracy: 0.9688 - val_loss: 0.0436 - val_binary_accuracy: 0.9686\n",
      "Epoch 8/20\n",
      "2437/2437 [==============================] - 10s 4ms/step - loss: 0.0435 - binary_accuracy: 0.9689 - val_loss: 0.0429 - val_binary_accuracy: 0.9705\n",
      "Epoch 9/20\n",
      "2437/2437 [==============================] - 10s 4ms/step - loss: 0.0315 - binary_accuracy: 0.9793 - val_loss: 0.0218 - val_binary_accuracy: 0.9846\n",
      "Epoch 10/20\n",
      "2437/2437 [==============================] - 10s 4ms/step - loss: 0.0218 - binary_accuracy: 0.9844 - val_loss: 0.0227 - val_binary_accuracy: 0.9844\n",
      "Epoch 11/20\n",
      "2437/2437 [==============================] - 10s 4ms/step - loss: 0.0218 - binary_accuracy: 0.9844 - val_loss: 0.0218 - val_binary_accuracy: 0.9844\n",
      "Epoch 12/20\n",
      "2437/2437 [==============================] - 9s 4ms/step - loss: 0.0218 - binary_accuracy: 0.9844 - val_loss: 0.0214 - val_binary_accuracy: 0.9844\n",
      "Epoch 13/20\n",
      "2437/2437 [==============================] - 9s 4ms/step - loss: 0.0145 - binary_accuracy: 0.9918 - val_loss: 0.0050 - val_binary_accuracy: 0.9983\n",
      "Epoch 14/20\n",
      "2437/2437 [==============================] - 10s 4ms/step - loss: 7.5179e-04 - binary_accuracy: 0.9998 - val_loss: 1.7931e-05 - val_binary_accuracy: 1.0000\n",
      "Epoch 15/20\n",
      "2437/2437 [==============================] - 10s 4ms/step - loss: 1.2088e-05 - binary_accuracy: 1.0000 - val_loss: 8.7980e-06 - val_binary_accuracy: 1.0000\n",
      "Epoch 16/20\n",
      "2437/2437 [==============================] - 10s 4ms/step - loss: 7.2180e-06 - binary_accuracy: 1.0000 - val_loss: 6.0739e-06 - val_binary_accuracy: 1.0000\n",
      "Epoch 17/20\n",
      "2437/2437 [==============================] - 9s 4ms/step - loss: 5.3111e-06 - binary_accuracy: 1.0000 - val_loss: 4.7124e-06 - val_binary_accuracy: 1.0000\n",
      "Epoch 18/20\n",
      "2437/2437 [==============================] - 9s 4ms/step - loss: 4.2605e-06 - binary_accuracy: 1.0000 - val_loss: 3.8841e-06 - val_binary_accuracy: 1.0000\n",
      "Epoch 19/20\n",
      "2437/2437 [==============================] - 9s 4ms/step - loss: 3.5836e-06 - binary_accuracy: 1.0000 - val_loss: 3.3235e-06 - val_binary_accuracy: 1.0000\n",
      "Epoch 20/20\n",
      "2437/2437 [==============================] - 10s 4ms/step - loss: 3.1083e-06 - binary_accuracy: 1.0000 - val_loss: 2.9156e-06 - val_binary_accuracy: 1.0000\n",
      "CPU times: total: 19min 38s\n",
      "Wall time: 3min 20s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "model = train_model(model, epochs=20,log_dir = \"tmp/mt_twisting_model/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40/40 [==============================] - 0s 2ms/step - loss: 1.3283e-08 - binary_accuracy: 1.0000\n",
      "test loss: 0.000000, test acc: 1.0\n"
     ]
    }
   ],
   "source": [
    "results = model.evaluate(X_test, y_test, batch_size=256)\n",
    "print(\"test loss: %f, test acc: %s\" % tuple(results))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"mt_twisting_model.h5\")"
   ]
  }
 ],
 "metadata": {
  "environment": {
   "name": "tf2-gpu.2-6.m81",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/tf2-gpu.2-6:m81"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "c979506cc9afdf8aa226c02a415aa6e55fb0b686ab6aba9022c7c04b1ee1b54e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
